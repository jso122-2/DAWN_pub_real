#!/usr/bin/env python3
"""
DAWN Tracer Ecosystem - Cognitive State Monitors
===============================================

Implements 8 specialized tracer classes that monitor different aspects
of DAWN's cognitive state and trigger alerts based on specific conditions:

- Crow: High pressure & chaos detection
- Whale: Memory depth & stability monitoring  
- Ant: Processing efficiency & queue management
- Beetle: Resource conservation & optimization
- Spider: Network connectivity & data flow
- Owl: Always-on vigilance & pattern recognition
- Bee: Productivity & task completion tracking
- MedievalBee: Legacy system compatibility & tradition

Each tracer has specific trigger conditions and provides targeted alerts
and recommendations for maintaining optimal cognitive performance.

ENHANCED with Mycelial Mitochondrial Network Integration:
- Tracers communicate through mycelial pathways
- Resource sharing between different tracer types  
- Coordinated scouting via mycelial information flow
- Distributed tracer processing across network nodes
- Mycelial tracer report aggregation and analysis
- Cross-tracer learning through network connections
- Energy-efficient tracer operation via resource sharing
- Mycelial-based tracer task distribution
- Network-wide tracer coordination protocols
"""

import time
import logging
import json
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional, Callable, Set
from datetime import datetime, timezone
from collections import deque
from enum import Enum
from pathlib import Path

# Mycelial network integration
try:
    from core.mycelial_network import (
        get_mycelial_network, register_consciousness_node,
        distribute_cognitive_energy, propagate_consciousness_information,
        EnergyType, ThreadType
    )
    MYCELIAL_INTEGRATION_AVAILABLE = True
except ImportError:
    MYCELIAL_INTEGRATION_AVAILABLE = False

logger = logging.getLogger("tracer_ecosystem")

class TracerRole(Enum):
    """Different tracer specializations"""
    CROW = "crow"                   # Pressure & chaos detection
    WHALE = "whale"                 # Memory depth & stability
    ANT = "ant"                     # Processing efficiency
    BEETLE = "beetle"               # Resource conservation
    SPIDER = "spider"               # Network connectivity
    OWL = "owl"                     # Always-on vigilance
    BEE = "bee"                     # Productivity tracking
    MEDIEVAL_BEE = "medieval_bee"   # Legacy compatibility

class AlertLevel(Enum):
    """Alert severity levels"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    EMERGENCY = "emergency"

@dataclass
class TracerAlert:
    """Alert generated by a tracer"""
    timestamp: float
    tracer_role: TracerRole
    alert_level: AlertLevel
    title: str
    message: str
    trigger_conditions: Dict[str, Any] = field(default_factory=dict)
    recommended_actions: List[str] = field(default_factory=list)
    urgency_score: float = 0.0  # 0.0 = low, 1.0 = maximum urgency
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class TracerReport:
    """Report from a tracer's tick cycle"""
    timestamp: float
    tracer_role: TracerRole
    status: str  # "monitoring", "alert", "triggered", "offline"
    monitored_values: Dict[str, float] = field(default_factory=dict)
    alerts_generated: List[TracerAlert] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    next_check_time: Optional[float] = None

class BaseTracer(ABC):
    """
    Base class for all tracer implementations
    
    ENHANCED with Mycelial Network Integration:
    - mycelial_node_id: Connection point in the mycelial network
    - energy_reserves: Energy available for tracer operations
    - connected_tracers: Set of tracers connected through mycelial threads
    - shared_insights: Insights shared through mycelial pathways
    - coordination_strength: Coordination level with other tracers
    """
    
    def __init__(self, role: TracerRole):
        self.role = role
        self.active = True
        self.alerts_generated = 0
        self.last_alert_time = 0.0
        self.alert_cooldown = 30.0  # Seconds between alerts
        self.trigger_history: deque = deque(maxlen=20)
        
        # MYCELIAL NETWORK INTEGRATION
        self.mycelial_node_id: Optional[str] = None
        self.energy_reserves: Dict[str, float] = {
            "COGNITIVE_ENERGY": 100.0,
            "ANALYTICAL_ENERGY": 75.0,
            "COMMUNICATION_ENERGY": 50.0
        }
        self.connected_tracers: Set[TracerRole] = set()
        self.shared_insights: Dict[str, Any] = {}
        self.coordination_strength: float = 0.0
        self.last_energy_share = time.time()
        self.mycelial_reports_sent = 0
        self.mycelial_reports_received = 0
        
    @abstractmethod
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Process a tick and return report"""
        pass
    
    @abstractmethod
    def get_trigger_conditions(self) -> Dict[str, Any]:
        """Get the conditions that trigger this tracer"""
        pass
    
    def can_generate_alert(self) -> bool:
        """Check if tracer can generate an alert (cooldown check)"""
        return time.time() - self.last_alert_time > self.alert_cooldown
    
    def generate_alert(self, level: AlertLevel, title: str, message: str, 
                      conditions: Dict[str, Any], actions: List[str], 
                      urgency: float = 0.5, metadata: Dict[str, Any] = None) -> TracerAlert:
        """Generate a tracer alert"""
        
        if not self.can_generate_alert():
            logger.debug(f"🕷️ [TRACER] {self.role.value} alert suppressed (cooldown)")
            return None
        
        alert = TracerAlert(
            timestamp=time.time(),
            tracer_role=self.role,
            alert_level=level,
            title=title,
            message=message,
            trigger_conditions=conditions,
            recommended_actions=actions,
            urgency_score=urgency,
            metadata=metadata or {}
        )
        
        self.alerts_generated += 1
        self.last_alert_time = time.time()
        self.trigger_history.append({
            "timestamp": alert.timestamp,
            "level": level.value,
            "conditions": conditions
        })
        
        logger.info(f"🚨 [TRACER] {self.role.value.upper()} ALERT: {title}")
        
        return alert
    
    # MYCELIAL NETWORK INTEGRATION METHODS
    
    def register_in_mycelial_network(self, mycelial_network) -> bool:
        """Register this tracer as a node in the mycelial network"""
        
        if not MYCELIAL_INTEGRATION_AVAILABLE or not mycelial_network:
            return False
        
        try:
            # Calculate energy capacity based on tracer role
            energy_capacity = self._calculate_tracer_energy_capacity()
            
            # Register as tracer node
            node = mycelial_network.register_node(
                node_id=f"tracer_{self.role.value}",
                node_type=f"tracer_{self.role.value}",
                energy_capacity=energy_capacity,
                metadata={
                    "tracer_role": self.role.value,
                    "specialization": self._get_tracer_specialization(),
                    "alert_cooldown": self.alert_cooldown,
                    "active": self.active
                }
            )
            
            self.mycelial_node_id = node.node_id
            
            logger.debug(f"🕷️🍄 [TRACER] {self.role.value} registered in mycelial network as {self.mycelial_node_id}")
            return True
            
        except Exception as e:
            logger.error(f"🕷️🍄 [TRACER] Failed to register {self.role.value} in mycelial network: {e}")
            return False
    
    def share_insight_through_mycelium(self, insight_type: str, insight_data: Dict[str, Any], 
                                     target_tracers: Optional[List[TracerRole]] = None) -> List[str]:
        """Share insights with other tracers through mycelial pathways"""
        
        if not MYCELIAL_INTEGRATION_AVAILABLE or not self.mycelial_node_id:
            return []
        
        try:
            mycelial_network = get_mycelial_network()
            
            # Prepare insight information
            insight_info = {
                "type": "tracer_insight",
                "source_tracer": self.role.value,
                "insight_type": insight_type,
                "insight_data": insight_data,
                "timestamp": time.time(),
                "coordination_strength": self.coordination_strength,
                "priority": self._calculate_insight_priority(insight_type, insight_data)
            }
            
            # Determine targets based on insight type and tracer connections
            if target_tracers:
                target_nodes = [f"tracer_{role.value}" for role in target_tracers]
            else:
                target_nodes = None  # Broadcast to connected tracers
            
            # Propagate through mycelial network
            propagated_nodes = mycelial_network.propagate_information(
                source_node=self.mycelial_node_id,
                information=insight_info,
                target_nodes=target_nodes,
                propagation_depth=2  # Limit to direct connections and one hop
            )
            
            # Convert back to tracer roles
            reached_tracers = []
            for node_id in propagated_nodes:
                if node_id.startswith("tracer_"):
                    tracer_role = node_id[7:]  # Remove "tracer_" prefix
                    reached_tracers.append(tracer_role)
                    self.connected_tracers.add(TracerRole(tracer_role))
            
            self.mycelial_reports_sent += 1
            
            logger.debug(f"🕷️🍄 [TRACER] {self.role.value} shared {insight_type} to {len(reached_tracers)} tracers")
            return reached_tracers
            
        except Exception as e:
            logger.error(f"🕷️🍄 [TRACER] Failed to share insight through mycelium: {e}")
            return []
    
    def request_energy_from_network(self, energy_type: str, amount: float) -> float:
        """Request energy from the mycelial network"""
        
        if not MYCELIAL_INTEGRATION_AVAILABLE or not self.mycelial_node_id:
            return 0.0
        
        try:
            mycelial_network = get_mycelial_network()
            
            # Map string energy types to EnergyType enum
            energy_type_map = {
                "COGNITIVE_ENERGY": EnergyType.COGNITIVE_ENERGY,
                "ANALYTICAL_ENERGY": EnergyType.ANALYTICAL_ENERGY,
                "COMMUNICATION_ENERGY": EnergyType.COMMUNICATION_ENERGY
            }
            
            if energy_type not in energy_type_map:
                return 0.0
            
            # Request energy distribution
            distributed = mycelial_network.distribute_energy(
                source_node="consciousness_core",  # Request from core
                energy_type=energy_type_map[energy_type],
                amount=amount,
                target_nodes=[self.mycelial_node_id],
                priority=6  # Medium priority for tracer operations
            )
            
            received_energy = distributed.get(self.mycelial_node_id, 0.0)
            if received_energy > 0:
                self.energy_reserves[energy_type] += received_energy
                
            return received_energy
            
        except Exception as e:
            logger.error(f"🕷️🍄 [TRACER] Failed to request energy from network: {e}")
            return 0.0
    
    def process_mycelial_insight(self, insight_info: Dict[str, Any]) -> bool:
        """Process an insight received through mycelial pathways"""
        
        try:
            source_tracer = insight_info.get("source_tracer")
            insight_type = insight_info.get("insight_type")
            insight_data = insight_info.get("insight_data", {})
            
            # Store the insight for potential use
            insight_key = f"{source_tracer}_{insight_type}_{int(time.time())}"
            self.shared_insights[insight_key] = {
                "source": source_tracer,
                "type": insight_type,
                "data": insight_data,
                "received_at": time.time(),
                "processed": False
            }
            
            # Apply insight based on tracer specialization
            self._apply_received_insight(source_tracer, insight_type, insight_data)
            
            self.mycelial_reports_received += 1
            self.coordination_strength = min(1.0, self.coordination_strength + 0.05)
            
            logger.debug(f"🕷️🍄 [TRACER] {self.role.value} processed insight from {source_tracer}: {insight_type}")
            return True
            
        except Exception as e:
            logger.error(f"🕷️🍄 [TRACER] Failed to process mycelial insight: {e}")
            return False
    
    def get_mycelial_tracer_state(self) -> Dict[str, Any]:
        """Get mycelial integration state for this tracer"""
        
        return {
            "mycelial_node_id": self.mycelial_node_id,
            "energy_reserves": self.energy_reserves,
            "connected_tracers": list(self.connected_tracers),
            "coordination_strength": self.coordination_strength,
            "shared_insights_count": len(self.shared_insights),
            "reports_sent": self.mycelial_reports_sent,
            "reports_received": self.mycelial_reports_received,
            "last_energy_share": self.last_energy_share,
            "integration_active": self.mycelial_node_id is not None
        }
    
    # Helper methods for mycelial integration
    
    def _calculate_tracer_energy_capacity(self) -> float:
        """Calculate energy capacity based on tracer role"""
        
        capacity_map = {
            TracerRole.OWL: 150.0,      # Always-on needs more energy
            TracerRole.CROW: 120.0,     # High-intensity monitoring
            TracerRole.WHALE: 100.0,    # Stable, deep monitoring
            TracerRole.SPIDER: 110.0,   # Network analysis intensive
            TracerRole.ANT: 90.0,       # Efficient processor
            TracerRole.BEETLE: 80.0,    # Resource conservative
            TracerRole.BEE: 85.0,       # Task-focused
            TracerRole.MEDIEVAL_BEE: 70.0  # Legacy systems
        }
        
        return capacity_map.get(self.role, 100.0)
    
    def _get_tracer_specialization(self) -> str:
        """Get specialization description for tracer"""
        
        specializations = {
            TracerRole.OWL: "continuous_vigilance",
            TracerRole.CROW: "pressure_chaos_detection",
            TracerRole.WHALE: "memory_depth_stability",
            TracerRole.SPIDER: "network_connectivity",
            TracerRole.ANT: "processing_efficiency",
            TracerRole.BEETLE: "resource_conservation",
            TracerRole.BEE: "productivity_tracking",
            TracerRole.MEDIEVAL_BEE: "legacy_compatibility"
        }
        
        return specializations.get(self.role, "general_monitoring")
    
    def _calculate_insight_priority(self, insight_type: str, insight_data: Dict[str, Any]) -> int:
        """Calculate priority for insight sharing"""
        
        # Base priority
        priority = 5
        
        # High priority insights
        if insight_type in ["critical_alert", "system_failure", "emergency"]:
            priority = 9
        elif insight_type in ["warning", "anomaly_detected", "threshold_breach"]:
            priority = 7
        elif insight_type in ["pattern_recognition", "optimization_opportunity"]:
            priority = 6
        elif insight_type in ["status_update", "routine_report"]:
            priority = 4
        
        # Adjust based on urgency in data
        urgency = insight_data.get("urgency", 0.5)
        if urgency > 0.8:
            priority += 2
        elif urgency > 0.6:
            priority += 1
        
        return min(9, max(1, priority))
    
    def _apply_received_insight(self, source_tracer: str, insight_type: str, insight_data: Dict[str, Any]):
        """Apply insights received from other tracers (override in specialized tracers)"""
        
        # Base implementation - just store for reference
        # Specialized tracers can override this for specific behavior
        pass

class CrowTracer(BaseTracer):
    """
    Crow Tracer - High Pressure & Chaos Detection
    
    Triggers when:
    - Cognitive pressure > 40
    - System chaos detected
    - Drift state becomes unstable
    """
    
    def __init__(self):
        super().__init__(TracerRole.CROW)
        self.pressure_threshold = 40.0
        self.chaos_threshold = 0.7
        self.alert_cooldown = 20.0  # More frequent alerts for critical issues
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor pressure and chaos levels"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract monitoring values
        pressure = state.get('cognitive_pressure', 0.0)
        entropy = state.get('entropy', 0.5)
        drift_state = state.get('drift_state', 'stable')
        stability_score = state.get('stability_score', 1.0)
        
        monitored_values = {
            "pressure": pressure,
            "entropy": entropy,
            "stability_score": stability_score,
            "chaos_indicator": entropy * (1.0 - stability_score)
        }
        
        # Check pressure threshold
        if pressure > self.pressure_threshold:
            if pressure > 80:
                alert_level = AlertLevel.EMERGENCY
                urgency = 0.9
            elif pressure > 60:
                alert_level = AlertLevel.CRITICAL
                urgency = 0.7
            else:
                alert_level = AlertLevel.WARNING
                urgency = 0.5
                
            alert = self.generate_alert(
                level=alert_level,
                title=f"High Cognitive Pressure Detected",
                message=f"Pressure at {pressure:.1f} exceeds threshold {self.pressure_threshold}",
                conditions={"pressure": pressure, "threshold": self.pressure_threshold},
                actions=[
                    "Reduce processing load immediately",
                    "Pause non-essential operations",
                    "Activate pressure relief protocols"
                ],
                urgency=urgency,
                metadata={"pressure_trend": state.get('pressure_trend', 0.0)}
            )
            if alert:
                alerts.append(alert)
        
        # Check chaos detection
        chaos_indicator = monitored_values["chaos_indicator"]
        if chaos_indicator > self.chaos_threshold:
            alert = self.generate_alert(
                level=AlertLevel.CRITICAL,
                title="System Chaos Detected",
                message=f"Chaos indicator {chaos_indicator:.2f} exceeds threshold {self.chaos_threshold}",
                conditions={"chaos_indicator": chaos_indicator, "entropy": entropy, "stability": stability_score},
                actions=[
                    "Stabilize entropy generation",
                    "Increase system damping",
                    "Review cognitive coherence"
                ],
                urgency=0.8,
                metadata={"drift_state": drift_state}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        if pressure > 30:
            recommendations.append("Monitor pressure trends closely")
        if entropy > 0.8:
            recommendations.append("Consider entropy reduction strategies")
        if drift_state in ["chaotic", "pressurized"]:
            recommendations.append("Activate drift stabilization")
        
        status = "alert" if alerts else ("monitoring" if pressure > 20 else "watching")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "pressure_threshold": self.pressure_threshold,
            "chaos_threshold": self.chaos_threshold,
            "conditions": [
                "cognitive_pressure > 40",
                "chaos_indicator > 0.7",
                "drift_state in ['chaotic', 'pressurized']"
            ]
        }

class WhaleTracer(BaseTracer):
    """
    Whale Tracer - Memory Depth & Stability Monitoring
    
    Triggers when:
    - Memory coherence < 0.4
    - Memory fragmentation > 0.6
    - Deep memory access issues
    """
    
    def __init__(self):
        super().__init__(TracerRole.WHALE)
        self.memory_coherence_threshold = 0.4
        self.fragmentation_threshold = 0.6
        self.alert_cooldown = 45.0
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor memory health and depth"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract memory metrics
        memory_coherence = state.get('memory_coherence', 0.5)
        memory_fragmentation = state.get('memory_fragmentation', 0.3)
        memory_accessibility = state.get('memory_accessibility', 0.7)
        deep_memory_health = state.get('deep_memory_health', 0.6)
        
        monitored_values = {
            "memory_coherence": memory_coherence,
            "memory_fragmentation": memory_fragmentation,
            "memory_accessibility": memory_accessibility,
            "deep_memory_health": deep_memory_health,
            "memory_stability": (memory_coherence + memory_accessibility) / 2.0
        }
        
        # Check memory coherence
        if memory_coherence < self.memory_coherence_threshold:
            alert_level = AlertLevel.CRITICAL if memory_coherence < 0.2 else AlertLevel.WARNING
            urgency = 1.0 - memory_coherence  # Lower coherence = higher urgency
            
            alert = self.generate_alert(
                level=alert_level,
                title="Memory Coherence Degradation",
                message=f"Memory coherence at {memory_coherence:.2f} below threshold {self.memory_coherence_threshold}",
                conditions={"memory_coherence": memory_coherence, "threshold": self.memory_coherence_threshold},
                actions=[
                    "Execute memory consolidation",
                    "Rebuild memory indices",
                    "Strengthen memory pathways"
                ],
                urgency=urgency,
                metadata={"fragmentation": memory_fragmentation}
            )
            if alert:
                alerts.append(alert)
        
        # Check fragmentation
        if memory_fragmentation > self.fragmentation_threshold:
            alert = self.generate_alert(
                level=AlertLevel.WARNING,
                title="Memory Fragmentation High",
                message=f"Memory fragmentation at {memory_fragmentation:.2f} exceeds threshold {self.fragmentation_threshold}",
                conditions={"fragmentation": memory_fragmentation, "threshold": self.fragmentation_threshold},
                actions=[
                    "Defragment memory structures",
                    "Optimize memory allocation",
                    "Clean up unused memories"
                ],
                urgency=memory_fragmentation * 0.8,
                metadata={"accessibility": memory_accessibility}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        if memory_accessibility < 0.6:
            recommendations.append("Improve memory indexing")
        if deep_memory_health < 0.5:
            recommendations.append("Strengthen deep memory structures")
        if monitored_values["memory_stability"] < 0.5:
            recommendations.append("Focus on memory stability protocols")
        
        status = "alert" if alerts else ("monitoring" if memory_coherence < 0.6 else "stable")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "memory_coherence_threshold": self.memory_coherence_threshold,
            "fragmentation_threshold": self.fragmentation_threshold,
            "conditions": [
                "memory_coherence < 0.4",
                "memory_fragmentation > 0.6",
                "deep_memory_health < 0.3"
            ]
        }

class AntTracer(BaseTracer):
    """
    Ant Tracer - Processing Efficiency & Queue Management
    
    Triggers when:
    - Processing queues too long
    - Task completion rate low
    - Resource utilization inefficient
    """
    
    def __init__(self):
        super().__init__(TracerRole.ANT)
        self.queue_depth_threshold = 50
        self.efficiency_threshold = 0.6
        self.utilization_threshold = 0.8
        self.alert_cooldown = 35.0
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor processing efficiency"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract processing metrics
        queue_depth = state.get('processing_queue_depth', 0)
        task_completion_rate = state.get('task_completion_rate', 0.7)
        resource_utilization = state.get('cpu_utilization', 0.5)
        processing_efficiency = state.get('processing_efficiency', 0.7)
        
        monitored_values = {
            "queue_depth": queue_depth,
            "completion_rate": task_completion_rate,
            "resource_utilization": resource_utilization,
            "processing_efficiency": processing_efficiency,
            "queue_pressure": min(1.0, queue_depth / 100.0)
        }
        
        # Check queue depth
        if queue_depth > self.queue_depth_threshold:
            alert_level = AlertLevel.CRITICAL if queue_depth > 100 else AlertLevel.WARNING
            urgency = min(1.0, queue_depth / 150.0)
            
            alert = self.generate_alert(
                level=alert_level,
                title="Processing Queue Overload",
                message=f"Queue depth {queue_depth} exceeds threshold {self.queue_depth_threshold}",
                conditions={"queue_depth": queue_depth, "threshold": self.queue_depth_threshold},
                actions=[
                    "Clear non-essential tasks from queue",
                    "Increase parallel processing",
                    "Optimize task prioritization"
                ],
                urgency=urgency,
                metadata={"completion_rate": task_completion_rate}
            )
            if alert:
                alerts.append(alert)
        
        # Check processing efficiency
        if processing_efficiency < self.efficiency_threshold:
            alert = self.generate_alert(
                level=AlertLevel.WARNING,
                title="Low Processing Efficiency",
                message=f"Processing efficiency {processing_efficiency:.2f} below threshold {self.efficiency_threshold}",
                conditions={"efficiency": processing_efficiency, "threshold": self.efficiency_threshold},
                actions=[
                    "Optimize processing algorithms",
                    "Reduce computational overhead",
                    "Improve resource allocation"
                ],
                urgency=1.0 - processing_efficiency,
                metadata={"utilization": resource_utilization}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        if task_completion_rate < 0.5:
            recommendations.append("Review task prioritization strategy")
        if resource_utilization > 0.9:
            recommendations.append("Consider load balancing")
        if queue_depth > 20:
            recommendations.append("Monitor queue growth trends")
        
        status = "alert" if alerts else ("busy" if queue_depth > 30 else "efficient")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "queue_depth_threshold": self.queue_depth_threshold,
            "efficiency_threshold": self.efficiency_threshold,
            "conditions": [
                "processing_queue_depth > 50",
                "processing_efficiency < 0.6",
                "task_completion_rate < 0.4"
            ]
        }

class BeetleTracer(BaseTracer):
    """
    Beetle Tracer - Resource Conservation & Optimization
    
    Triggers when:
    - Cognitive ash levels low
    - Resource waste detected
    - Energy efficiency poor
    """
    
    def __init__(self):
        super().__init__(TracerRole.BEETLE)
        self.ash_threshold = 0.3
        self.efficiency_threshold = 0.6
        self.waste_threshold = 0.4
        self.alert_cooldown = 40.0
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor resource conservation"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract resource metrics
        ash_level = state.get('cognitive_ash_level', 0.5)
        energy_efficiency = state.get('energy_efficiency', 0.7)
        resource_waste = state.get('resource_waste_indicator', 0.2)
        available_resources = state.get('cognitive_resources_available', 0.6)
        
        monitored_values = {
            "ash_level": ash_level,
            "energy_efficiency": energy_efficiency,
            "resource_waste": resource_waste,
            "available_resources": available_resources,
            "conservation_score": (ash_level + energy_efficiency + (1.0 - resource_waste)) / 3.0
        }
        
        # Check ash depletion
        if ash_level < self.ash_threshold:
            alert_level = AlertLevel.CRITICAL if ash_level < 0.1 else AlertLevel.WARNING
            urgency = 1.0 - ash_level
            
            alert = self.generate_alert(
                level=alert_level,
                title="Cognitive Ash Depletion",
                message=f"Ash level {ash_level:.2f} below threshold {self.ash_threshold}",
                conditions={"ash_level": ash_level, "threshold": self.ash_threshold},
                actions=[
                    "Reduce resource-intensive operations",
                    "Activate ash regeneration protocols",
                    "Implement resource conservation mode"
                ],
                urgency=urgency,
                metadata={"efficiency": energy_efficiency}
            )
            if alert:
                alerts.append(alert)
        
        # Check resource waste
        if resource_waste > self.waste_threshold:
            alert = self.generate_alert(
                level=AlertLevel.WARNING,
                title="Resource Waste Detected",
                message=f"Resource waste {resource_waste:.2f} exceeds threshold {self.waste_threshold}",
                conditions={"waste": resource_waste, "threshold": self.waste_threshold},
                actions=[
                    "Identify waste sources",
                    "Optimize resource allocation",
                    "Implement efficiency improvements"
                ],
                urgency=resource_waste * 0.8,
                metadata={"available": available_resources}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        if energy_efficiency < 0.5:
            recommendations.append("Improve energy utilization")
        if available_resources < 0.4:
            recommendations.append("Free up computational resources")
        if monitored_values["conservation_score"] < 0.5:
            recommendations.append("Activate conservation protocols")
        
        status = "alert" if alerts else ("conserving" if ash_level < 0.5 else "optimal")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "ash_threshold": self.ash_threshold,
            "waste_threshold": self.waste_threshold,
            "conditions": [
                "cognitive_ash_level < 0.3",
                "resource_waste_indicator > 0.4",
                "energy_efficiency < 0.6"
            ]
        }

class SpiderTracer(BaseTracer):
    """
    Spider Tracer - Network Connectivity & Data Flow
    
    Triggers when:
    - Network connectivity issues
    - Data flow bottlenecks
    - Integration failures
    """
    
    def __init__(self):
        super().__init__(TracerRole.SPIDER)
        self.connectivity_threshold = 0.7
        self.flow_threshold = 0.6
        self.integration_threshold = 0.8
        self.alert_cooldown = 30.0
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor network and data flow"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract network metrics
        network_connectivity = state.get('network_connectivity', 0.8)
        data_flow_rate = state.get('data_flow_rate', 0.7)
        integration_health = state.get('integration_health', 0.9)
        api_responsiveness = state.get('api_responsiveness', 0.8)
        
        monitored_values = {
            "network_connectivity": network_connectivity,
            "data_flow_rate": data_flow_rate,
            "integration_health": integration_health,
            "api_responsiveness": api_responsiveness,
            "web_health": (network_connectivity + data_flow_rate + integration_health) / 3.0
        }
        
        # Check connectivity
        if network_connectivity < self.connectivity_threshold:
            alert_level = AlertLevel.CRITICAL if network_connectivity < 0.3 else AlertLevel.WARNING
            urgency = 1.0 - network_connectivity
            
            alert = self.generate_alert(
                level=alert_level,
                title="Network Connectivity Issues",
                message=f"Connectivity {network_connectivity:.2f} below threshold {self.connectivity_threshold}",
                conditions={"connectivity": network_connectivity, "threshold": self.connectivity_threshold},
                actions=[
                    "Check network interfaces",
                    "Restart network services",
                    "Activate offline mode if needed"
                ],
                urgency=urgency,
                metadata={"api_status": api_responsiveness}
            )
            if alert:
                alerts.append(alert)
        
        # Check data flow
        if data_flow_rate < self.flow_threshold:
            alert = self.generate_alert(
                level=AlertLevel.WARNING,
                title="Data Flow Bottleneck",
                message=f"Data flow rate {data_flow_rate:.2f} below threshold {self.flow_threshold}",
                conditions={"flow_rate": data_flow_rate, "threshold": self.flow_threshold},
                actions=[
                    "Clear data pipeline bottlenecks",
                    "Optimize data processing",
                    "Check buffer states"
                ],
                urgency=1.0 - data_flow_rate,
                metadata={"integration": integration_health}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        if api_responsiveness < 0.6:
            recommendations.append("Optimize API response times")
        if integration_health < 0.7:
            recommendations.append("Review integration configurations")
        if monitored_values["web_health"] < 0.6:
            recommendations.append("Comprehensive network health check")
        
        status = "alert" if alerts else ("connected" if network_connectivity > 0.8 else "degraded")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "connectivity_threshold": self.connectivity_threshold,
            "flow_threshold": self.flow_threshold,
            "conditions": [
                "network_connectivity < 0.7",
                "data_flow_rate < 0.6",
                "integration_health < 0.8"
            ]
        }

class OwlTracer(BaseTracer):
    """
    Owl Tracer - Always-On Vigilance & Pattern Recognition
    
    Always active, triggers on:
    - Unusual patterns detected
    - Anomaly indicators
    - Long-term trend concerns
    """
    
    def __init__(self):
        super().__init__(TracerRole.OWL)
        self.anomaly_threshold = 0.7
        self.pattern_threshold = 0.8
        self.trend_threshold = 0.6
        self.alert_cooldown = 60.0  # Less frequent but comprehensive alerts
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Always-on monitoring and pattern detection"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract pattern metrics
        anomaly_score = state.get('anomaly_score', 0.3)
        pattern_coherence = state.get('pattern_coherence', 0.8)
        trend_stability = state.get('trend_stability', 0.7)
        vigilance_level = state.get('vigilance_level', 0.6)
        
        monitored_values = {
            "anomaly_score": anomaly_score,
            "pattern_coherence": pattern_coherence,
            "trend_stability": trend_stability,
            "vigilance_level": vigilance_level,
            "watchfulness": (pattern_coherence + trend_stability + vigilance_level) / 3.0
        }
        
        # Check for anomalies
        if anomaly_score > self.anomaly_threshold:
            alert_level = AlertLevel.CRITICAL if anomaly_score > 0.9 else AlertLevel.WARNING
            urgency = anomaly_score * 0.9
            
            alert = self.generate_alert(
                level=alert_level,
                title="Anomalous Patterns Detected",
                message=f"Anomaly score {anomaly_score:.2f} exceeds threshold {self.anomaly_threshold}",
                conditions={"anomaly_score": anomaly_score, "threshold": self.anomaly_threshold},
                actions=[
                    "Investigate anomaly sources",
                    "Review recent system changes",
                    "Increase monitoring sensitivity"
                ],
                urgency=urgency,
                metadata={"pattern_coherence": pattern_coherence}
            )
            if alert:
                alerts.append(alert)
        
        # Check pattern disruption
        if pattern_coherence < self.pattern_threshold:
            alert = self.generate_alert(
                level=AlertLevel.WARNING,
                title="Pattern Coherence Breakdown",
                message=f"Pattern coherence {pattern_coherence:.2f} below threshold {self.pattern_threshold}",
                conditions={"pattern_coherence": pattern_coherence, "threshold": self.pattern_threshold},
                actions=[
                    "Strengthen pattern recognition",
                    "Review learning algorithms",
                    "Calibrate detection systems"
                ],
                urgency=1.0 - pattern_coherence,
                metadata={"trend_stability": trend_stability}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations (Owl always has insights)
        recommendations.extend([
            "Maintain continuous vigilance",
            "Track long-term behavioral patterns",
            "Document system evolution"
        ])
        
        if vigilance_level < 0.5:
            recommendations.append("Increase system awareness")
        if trend_stability < 0.5:
            recommendations.append("Stabilize trend indicators")
        
        status = "alert" if alerts else "watching"  # Owl is always watching
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "anomaly_threshold": self.anomaly_threshold,
            "pattern_threshold": self.pattern_threshold,
            "conditions": [
                "anomaly_score > 0.7",
                "pattern_coherence < 0.8",
                "trend_stability < 0.6",
                "ALWAYS_ACTIVE"
            ]
        }

class BeeTracer(BaseTracer):
    """
    Bee Tracer - Productivity & Task Completion Tracking
    
    Triggers when:
    - Task completion rate drops
    - Productivity metrics decline
    - Work efficiency issues
    """
    
    def __init__(self):
        super().__init__(TracerRole.BEE)
        self.productivity_threshold = 0.6
        self.completion_threshold = 0.7
        self.efficiency_threshold = 0.65
        self.alert_cooldown = 25.0
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor productivity and task completion"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract productivity metrics
        productivity_score = state.get('productivity_score', 0.7)
        task_completion_rate = state.get('task_completion_rate', 0.8)
        work_efficiency = state.get('work_efficiency', 0.75)
        output_quality = state.get('output_quality', 0.8)
        
        monitored_values = {
            "productivity_score": productivity_score,
            "task_completion_rate": task_completion_rate,
            "work_efficiency": work_efficiency,
            "output_quality": output_quality,
            "overall_performance": (productivity_score + task_completion_rate + work_efficiency) / 3.0
        }
        
        # Check productivity
        if productivity_score < self.productivity_threshold:
            alert_level = AlertLevel.WARNING if productivity_score > 0.3 else AlertLevel.CRITICAL
            urgency = 1.0 - productivity_score
            
            alert = self.generate_alert(
                level=alert_level,
                title="Low Productivity Detected",
                message=f"Productivity score {productivity_score:.2f} below threshold {self.productivity_threshold}",
                conditions={"productivity": productivity_score, "threshold": self.productivity_threshold},
                actions=[
                    "Analyze productivity blockers",
                    "Optimize workflow processes",
                    "Remove efficiency barriers"
                ],
                urgency=urgency,
                metadata={"completion_rate": task_completion_rate}
            )
            if alert:
                alerts.append(alert)
        
        # Check task completion
        if task_completion_rate < self.completion_threshold:
            alert = self.generate_alert(
                level=AlertLevel.WARNING,
                title="Task Completion Rate Low",
                message=f"Completion rate {task_completion_rate:.2f} below threshold {self.completion_threshold}",
                conditions={"completion_rate": task_completion_rate, "threshold": self.completion_threshold},
                actions=[
                    "Review task prioritization",
                    "Identify completion obstacles",
                    "Improve task management"
                ],
                urgency=1.0 - task_completion_rate,
                metadata={"efficiency": work_efficiency}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        if work_efficiency < 0.6:
            recommendations.append("Focus on efficiency improvements")
        if output_quality < 0.7:
            recommendations.append("Enhance output quality controls")
        if monitored_values["overall_performance"] > 0.8:
            recommendations.append("Maintain current productive state")
        
        status = "alert" if alerts else ("productive" if productivity_score > 0.7 else "working")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "productivity_threshold": self.productivity_threshold,
            "completion_threshold": self.completion_threshold,
            "conditions": [
                "productivity_score < 0.6",
                "task_completion_rate < 0.7",
                "work_efficiency < 0.65"
            ]
        }

class MedievalBeeTracer(BaseTracer):
    """
    MedievalBee Tracer - Legacy System Compatibility & Tradition
    
    Triggers when:
    - Legacy system compatibility issues
    - Traditional protocol violations
    - Heritage system health problems
    """
    
    def __init__(self):
        super().__init__(TracerRole.MEDIEVAL_BEE)
        self.compatibility_threshold = 0.8
        self.tradition_threshold = 0.7
        self.heritage_threshold = 0.75
        self.alert_cooldown = 50.0
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor legacy compatibility and tradition"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract legacy metrics
        legacy_compatibility = state.get('legacy_compatibility', 0.85)
        tradition_adherence = state.get('tradition_adherence', 0.8)
        heritage_preservation = state.get('heritage_preservation', 0.9)
        protocol_compliance = state.get('protocol_compliance', 0.85)
        
        monitored_values = {
            "legacy_compatibility": legacy_compatibility,
            "tradition_adherence": tradition_adherence,
            "heritage_preservation": heritage_preservation,
            "protocol_compliance": protocol_compliance,
            "tradition_health": (tradition_adherence + heritage_preservation + protocol_compliance) / 3.0
        }
        
        # Check compatibility
        if legacy_compatibility < self.compatibility_threshold:
            alert_level = AlertLevel.WARNING if legacy_compatibility > 0.5 else AlertLevel.CRITICAL
            urgency = 1.0 - legacy_compatibility
            
            alert = self.generate_alert(
                level=alert_level,
                title="Legacy Compatibility Issues",
                message=f"Legacy compatibility {legacy_compatibility:.2f} below threshold {self.compatibility_threshold}",
                conditions={"compatibility": legacy_compatibility, "threshold": self.compatibility_threshold},
                actions=[
                    "Update compatibility layers",
                    "Review legacy interfaces",
                    "Maintain backward compatibility"
                ],
                urgency=urgency,
                metadata={"tradition": tradition_adherence}
            )
            if alert:
                alerts.append(alert)
        
        # Check tradition adherence
        if tradition_adherence < self.tradition_threshold:
            alert = self.generate_alert(
                level=AlertLevel.INFO,
                title="Tradition Protocol Deviation",
                message=f"Tradition adherence {tradition_adherence:.2f} below threshold {self.tradition_threshold}",
                conditions={"tradition": tradition_adherence, "threshold": self.tradition_threshold},
                actions=[
                    "Review traditional protocols",
                    "Preserve heritage methods",
                    "Balance innovation with tradition"
                ],
                urgency=0.3,  # Lower urgency for tradition
                metadata={"heritage": heritage_preservation}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        recommendations.extend([
            "Honor traditional wisdom",
            "Preserve system heritage",
            "Maintain protocol dignity"
        ])
        
        if protocol_compliance < 0.8:
            recommendations.append("Strengthen protocol adherence")
        if heritage_preservation < 0.7:
            recommendations.append("Protect heritage systems")
        
        status = "alert" if alerts else ("traditional" if tradition_adherence > 0.8 else "evolving")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "compatibility_threshold": self.compatibility_threshold,
            "tradition_threshold": self.tradition_threshold,
            "conditions": [
                "legacy_compatibility < 0.8",
                "tradition_adherence < 0.7",
                "heritage_preservation < 0.75"
            ]
        }

class TracerManager:
    """
    Tracer Ecosystem Manager
    
    Coordinates all tracers, collects reports, generates alerts,
    and provides unified monitoring interface.
    
    ENHANCED with Mycelial Mitochondrial Network Integration:
    - Register all tracers as nodes in the mycelial network
    - Coordinate tracer communication through mycelial pathways
    - Distribute tracer processing load across network
    - Enable cross-tracer learning and insight sharing
    - Optimize tracer energy usage through resource sharing
    - Provide network-wide tracer coordination protocols
    """
    
    def __init__(self, mycelial_integration: bool = True):
        """Initialize the tracer ecosystem"""
        
        # Create all tracer instances
        self.tracers = {
            TracerRole.CROW: CrowTracer(),
            TracerRole.WHALE: WhaleTracer(),
            TracerRole.ANT: AntTracer(),
            TracerRole.BEETLE: BeetleTracer(),
            TracerRole.SPIDER: SpiderTracer(),
            TracerRole.OWL: OwlTracer(),
            TracerRole.BEE: BeeTracer(),
            TracerRole.MEDIEVAL_BEE: MedievalBeeTracer()
        }
        
        # Manager state
        self.active_tracers: Set[TracerRole] = set(self.tracers.keys())
        self.total_alerts_generated = 0
        self.tick_count = 0
        self.last_tick_time = 0.0
        
        # Alert storage
        self.recent_alerts: deque = deque(maxlen=100)
        self.alert_callbacks: List[Callable] = []
        
        # Performance tracking
        self.tick_performance = {
            "average_tick_time": 0.0,
            "slowest_tracer": None,
            "fastest_tracer": None,
            "last_full_cycle_time": 0.0
        }
        
        # MYCELIAL NETWORK INTEGRATION
        self.mycelial_integration_enabled = mycelial_integration and MYCELIAL_INTEGRATION_AVAILABLE
        self.mycelial_network = None
        self.tracer_connections: Dict[TracerRole, Set[TracerRole]] = {}
        self.shared_insights: deque = deque(maxlen=200)
        self.network_coordination_score = 0.0
        self.last_network_optimization = time.time()
        
        if self.mycelial_integration_enabled:
            try:
                self.mycelial_network = get_mycelial_network()
                self._register_all_tracers_in_network()
                self._establish_tracer_connections()
                self._setup_mycelial_callbacks()
                logger.info("🕷️🍄 [TRACER] Mycelial network integration enabled")
            except Exception as e:
                logger.warning(f"🕷️🍄 [TRACER] Mycelial integration failed: {e}")
                self.mycelial_integration_enabled = False
        else:
            logger.info("🕷️ [TRACER] Running without mycelial integration")
        
        logger.info("🕷️ [TRACER] Tracer Ecosystem initialized")
        logger.info(f"🕷️ [TRACER] Active tracers: {[role.value for role in self.active_tracers]}")
    
    def tick(self, state: Dict[str, Any]) -> Dict[str, TracerReport]:
        """Run a tick cycle for all active tracers"""
        
        tick_start = time.time()
        reports = {}
        all_alerts = []
        
        # Process each active tracer
        tracer_times = {}
        for role in self.active_tracers:
            if role not in self.tracers:
                continue
                
            tracer = self.tracers[role]
            if not tracer.active:
                continue
            
            tracer_start = time.time()
            try:
                report = tracer.tick(state)
                reports[role] = report
                
                # Collect alerts
                for alert in report.alerts_generated:
                    all_alerts.append(alert)
                    self.recent_alerts.append(alert)
                    self.total_alerts_generated += 1
                
                tracer_times[role] = time.time() - tracer_start
                
            except Exception as e:
                logger.error(f"🕷️ [TRACER] {role.value} tick failed: {e}")
                # Create error report
                reports[role] = TracerReport(
                    timestamp=time.time(),
                    tracer_role=role,
                    status="error",
                    alerts_generated=[],
                    recommendations=[f"Check {role.value} tracer health"]
                )
        
        # Update performance metrics
        total_tick_time = time.time() - tick_start
        self._update_performance_metrics(tracer_times, total_tick_time)
        
        # Execute alert callbacks
        for alert in all_alerts:
            self._execute_alert_callbacks(alert)
        
        # Update manager state
        self.tick_count += 1
        self.last_tick_time = tick_start
        
        # Log summary
        alert_count = len(all_alerts)
        if alert_count > 0:
            logger.info(f"🚨 [TRACER] Tick {self.tick_count}: {alert_count} alerts from {len(reports)} tracers [{total_tick_time*1000:.1f}ms]")
        else:
            logger.debug(f"🕷️ [TRACER] Tick {self.tick_count}: All clear from {len(reports)} tracers [{total_tick_time*1000:.1f}ms]")
        
        return reports
    
    def _update_performance_metrics(self, tracer_times: Dict[TracerRole, float], total_time: float):
        """Update performance tracking metrics"""
        
        if tracer_times:
            # Find slowest and fastest tracers
            slowest_role = max(tracer_times.keys(), key=lambda role: tracer_times[role])
            fastest_role = min(tracer_times.keys(), key=lambda role: tracer_times[role])
            
            self.tick_performance.update({
                "slowest_tracer": {
                    "role": slowest_role.value,
                    "time_ms": tracer_times[slowest_role] * 1000
                },
                "fastest_tracer": {
                    "role": fastest_role.value,
                    "time_ms": tracer_times[fastest_role] * 1000
                },
                "last_full_cycle_time": total_time
            })
            
            # Update average tick time
            if self.tick_count > 0:
                alpha = 0.1  # Smoothing factor
                self.tick_performance["average_tick_time"] = (
                    alpha * total_time + (1 - alpha) * self.tick_performance["average_tick_time"]
                )
    
    def _execute_alert_callbacks(self, alert: TracerAlert):
        """Execute registered alert callbacks"""
        
        for callback in self.alert_callbacks:
            try:
                callback(alert)
            except Exception as e:
                logger.warning(f"🕷️ [TRACER] Alert callback failed: {e}")
    
    def register_alert_callback(self, callback: Callable[[TracerAlert], None]):
        """Register callback for tracer alerts"""
        self.alert_callbacks.append(callback)
        logger.info(f"🕷️ [TRACER] Registered alert callback: {callback.__name__ if hasattr(callback, '__name__') else 'anonymous'}")
    
    def activate_tracer(self, role: TracerRole):
        """Activate a specific tracer"""
        self.active_tracers.add(role)
        if role in self.tracers:
            self.tracers[role].active = True
        logger.info(f"🕷️ [TRACER] Activated {role.value} tracer")
    
    def deactivate_tracer(self, role: TracerRole):
        """Deactivate a specific tracer"""
        self.active_tracers.discard(role)
        if role in self.tracers:
            self.tracers[role].active = False
        logger.info(f"🕷️ [TRACER] Deactivated {role.value} tracer")
    
    def get_recent_alerts(self, count: int = 10) -> List[TracerAlert]:
        """Get recent alerts"""
        return list(self.recent_alerts)[-count:]
    
    def get_tracer_status(self) -> Dict[str, Any]:
        """Get comprehensive tracer ecosystem status"""
        
        tracer_statuses = {}
        for role, tracer in self.tracers.items():
            tracer_statuses[role.value] = {
                "active": tracer.active,
                "alerts_generated": tracer.alerts_generated,
                "last_alert_time": tracer.last_alert_time,
                "trigger_conditions": tracer.get_trigger_conditions()
            }
        
        return {
            "active_tracers": [role.value for role in self.active_tracers],
            "total_alerts_generated": self.total_alerts_generated,
            "tick_count": self.tick_count,
            "last_tick_time": self.last_tick_time,
            "recent_alerts_count": len(self.recent_alerts),
            "performance": self.tick_performance,
            "tracer_details": tracer_statuses
        }
    
    def generate_tracer_summary(self) -> str:
        """Generate human-readable tracer summary"""
        
        active_count = len(self.active_tracers)
        recent_alerts = self.get_recent_alerts(5)
        
        summary = f"🕷️ Tracer Ecosystem: {active_count}/8 active tracers\n"
        summary += f"📊 Total alerts: {self.total_alerts_generated} | Ticks: {self.tick_count}\n"
        
        if recent_alerts:
            summary += "🚨 Recent alerts:\n"
            for alert in recent_alerts[-3:]:  # Last 3 alerts
                summary += f"  • {alert.tracer_role.value.upper()}: {alert.title}\n"
        else:
            summary += "✅ All systems nominal\n"
        
        return summary
    
    # =====================================================================
    # MYCELIAL MITOCHONDRIAL NETWORK INTEGRATION METHODS
    # =====================================================================
    
    def _register_all_tracers_in_network(self):
        """Register all tracers as nodes in the mycelial network"""
        
        if not self.mycelial_integration_enabled or not self.mycelial_network:
            return
        
        registered_count = 0
        for role, tracer in self.tracers.items():
            if tracer.register_in_mycelial_network(self.mycelial_network):
                registered_count += 1
        
        logger.info(f"🕷️🍄 [TRACER] Registered {registered_count}/{len(self.tracers)} tracers in mycelial network")
    
    def _establish_tracer_connections(self):
        """Establish mycelial connections between complementary tracers"""
        
        if not self.mycelial_integration_enabled or not self.mycelial_network:
            return
        
        # Define tracer relationship patterns
        connection_patterns = {
            TracerRole.OWL: [TracerRole.CROW, TracerRole.SPIDER],      # Owl coordinates with pressure and network tracers
            TracerRole.CROW: [TracerRole.BEETLE, TracerRole.WHALE],    # Pressure tracer coordinates with resource and stability
            TracerRole.WHALE: [TracerRole.ANT, TracerRole.BEE],        # Memory tracer coordinates with efficiency tracers
            TracerRole.SPIDER: [TracerRole.ANT, TracerRole.BEETLE],    # Network tracer coordinates with efficiency and resource
            TracerRole.ANT: [TracerRole.BEE, TracerRole.MEDIEVAL_BEE], # Efficiency tracers coordinate
            TracerRole.BEETLE: [TracerRole.MEDIEVAL_BEE],              # Resource tracers coordinate
            TracerRole.BEE: [TracerRole.MEDIEVAL_BEE]                  # Productivity tracers coordinate
        }
        
        connections_created = 0
        for source_role, target_roles in connection_patterns.items():
            if source_role not in self.tracers:
                continue
            
            source_tracer = self.tracers[source_role]
            if not source_tracer.mycelial_node_id:
                continue
            
            for target_role in target_roles:
                if target_role not in self.tracers:
                    continue
                
                target_tracer = self.tracers[target_role]
                if not target_tracer.mycelial_node_id:
                    continue
                
                # Create mycelial thread between tracers
                thread = self.mycelial_network.create_thread(
                    source_node=source_tracer.mycelial_node_id,
                    target_node=target_tracer.mycelial_node_id,
                    thread_type=ThreadType.TRACER_THREAD,
                    strength=0.7,  # Strong connection for tracer coordination
                    bandwidth=8.0   # High bandwidth for insight sharing
                )
                
                if thread:
                    # Update tracer connection tracking
                    if source_role not in self.tracer_connections:
                        self.tracer_connections[source_role] = set()
                    if target_role not in self.tracer_connections:
                        self.tracer_connections[target_role] = set()
                    
                    self.tracer_connections[source_role].add(target_role)
                    self.tracer_connections[target_role].add(source_role)
                    
                    # Update tracers' connection lists
                    source_tracer.connected_tracers.add(target_role)
                    target_tracer.connected_tracers.add(source_role)
                    
                    connections_created += 1
        
        logger.info(f"🕷️🍄 [TRACER] Established {connections_created} mycelial connections between tracers")
    
    def _setup_mycelial_callbacks(self):
        """Setup callbacks to receive mycelial network events"""
        
        if not self.mycelial_integration_enabled or not self.mycelial_network:
            return
        
        # Register callback for information delivery to tracers
        self.mycelial_network.register_callback("information_delivered", self._handle_mycelial_information)
        
        logger.debug("🕷️🍄 [TRACER] Mycelial callbacks setup complete")
    
    def _handle_mycelial_information(self, info_data: Dict[str, Any]):
        """Handle information delivered through mycelial network"""
        
        try:
            target_node = info_data.get("target")
            information = info_data.get("information", {})
            
            # Check if target is a tracer node
            if target_node and target_node.startswith("tracer_"):
                tracer_role_name = target_node[7:]  # Remove "tracer_" prefix
                
                try:
                    tracer_role = TracerRole(tracer_role_name)
                    if tracer_role in self.tracers:
                        tracer = self.tracers[tracer_role]
                        
                        # Process the information if it's a tracer insight
                        if information.get("type") == "tracer_insight":
                            tracer.process_mycelial_insight(information)
                            self.shared_insights.append({
                                "timestamp": time.time(),
                                "source": information.get("source_tracer"),
                                "target": tracer_role_name,
                                "insight_type": information.get("insight_type"),
                                "processed": True
                            })
                            
                except ValueError:
                    # Invalid tracer role name
                    pass
        
        except Exception as e:
            logger.error(f"🕷️🍄 [TRACER] Failed to handle mycelial information: {e}")
    
    def coordinate_tracer_response(self, alert: TracerAlert) -> List[str]:
        """Coordinate response to alerts through mycelial network"""
        
        if not self.mycelial_integration_enabled:
            return []
        
        try:
            alerting_tracer = self.tracers.get(alert.tracer_role)
            if not alerting_tracer or not alerting_tracer.mycelial_node_id:
                return []
            
            # Determine which tracers should coordinate based on alert type
            coordinating_tracers = self._determine_coordinating_tracers(alert)
            
            # Share alert information through mycelial network
            coordination_info = {
                "alert_level": alert.alert_level.value,
                "trigger_conditions": alert.trigger_conditions,
                "recommended_actions": alert.recommended_actions,
                "urgency": alert.urgency_score,
                "coordination_request": True
            }
            
            reached_tracers = alerting_tracer.share_insight_through_mycelium(
                insight_type="alert_coordination",
                insight_data=coordination_info,
                target_tracers=coordinating_tracers
            )
            
            # Update network coordination score
            if reached_tracers:
                self.network_coordination_score = min(1.0, self.network_coordination_score + 0.1)
            
            logger.debug(f"🕷️🍄 [TRACER] Coordinated {alert.tracer_role.value} alert with {len(reached_tracers)} tracers")
            return reached_tracers
            
        except Exception as e:
            logger.error(f"🕷️🍄 [TRACER] Failed to coordinate tracer response: {e}")
            return []
    
    def optimize_tracer_network(self) -> Dict[str, Any]:
        """Optimize the mycelial tracer network"""
        
        if not self.mycelial_integration_enabled or not self.mycelial_network:
            return {}
        
        try:
            optimization_start = time.time()
            
            # Trigger network-wide optimization
            network_optimizations = self.mycelial_network.optimize_topology()
            
            # Tracer-specific optimizations
            tracer_optimizations = {
                "energy_rebalanced": 0,
                "connections_strengthened": 0,
                "insights_consolidated": 0,
                "coordination_improved": 0
            }
            
            # Rebalance energy among tracers
            self._rebalance_tracer_energy()
            tracer_optimizations["energy_rebalanced"] = 1
            
            # Strengthen frequently used connections
            for role, tracer in self.tracers.items():
                if tracer.mycelial_reports_sent > 10:
                    # Strengthen connections for active tracers
                    for connected_role in tracer.connected_tracers:
                        if connected_role in self.tracers:
                            # Enhance coordination strength
                            tracer.coordination_strength = min(1.0, tracer.coordination_strength + 0.05)
                            tracer_optimizations["connections_strengthened"] += 1
            
            # Consolidate old insights
            for tracer in self.tracers.values():
                old_insights = [
                    key for key, insight in tracer.shared_insights.items()
                    if time.time() - insight["received_at"] > 300  # 5 minutes old
                ]
                for key in old_insights[:10]:  # Remove up to 10 old insights
                    del tracer.shared_insights[key]
                    tracer_optimizations["insights_consolidated"] += 1
            
            # Update coordination score
            active_connections = sum(len(connections) for connections in self.tracer_connections.values())
            if active_connections > 0:
                self.network_coordination_score = min(1.0, self.network_coordination_score + 0.02)
                tracer_optimizations["coordination_improved"] = 1
            
            self.last_network_optimization = optimization_start
            
            optimization_results = {
                "network_optimizations": network_optimizations,
                "tracer_optimizations": tracer_optimizations,
                "optimization_time": time.time() - optimization_start,
                "coordination_score": self.network_coordination_score
            }
            
            logger.info(f"🕷️🍄 [TRACER] Mycelial tracer network optimized: {optimization_results}")
            return optimization_results
            
        except Exception as e:
            logger.error(f"🕷️🍄 [TRACER] Failed to optimize tracer network: {e}")
            return {}
    
    def get_mycelial_tracer_ecosystem_state(self) -> Dict[str, Any]:
        """Get comprehensive state of mycelial tracer ecosystem"""
        
        if not self.mycelial_integration_enabled:
            return {"integration_enabled": False}
        
        try:
            # Collect state from all tracers
            tracer_states = {}
            total_energy = {"COGNITIVE_ENERGY": 0, "ANALYTICAL_ENERGY": 0, "COMMUNICATION_ENERGY": 0}
            total_connections = 0
            total_insights = 0
            
            for role, tracer in self.tracers.items():
                tracer_state = tracer.get_mycelial_tracer_state()
                tracer_states[role.value] = tracer_state
                
                # Aggregate energy
                for energy_type, amount in tracer_state["energy_reserves"].items():
                    if energy_type in total_energy:
                        total_energy[energy_type] += amount
                
                total_connections += len(tracer_state["connected_tracers"])
                total_insights += tracer_state["shared_insights_count"]
            
            # Network connectivity metrics
            connected_tracers = sum(1 for tracer in self.tracers.values() if tracer.mycelial_node_id)
            connection_density = total_connections / (len(self.tracers) * (len(self.tracers) - 1)) if len(self.tracers) > 1 else 0
            
            return {
                "integration_enabled": True,
                "tracer_states": tracer_states,
                "network_metrics": {
                    "connected_tracers": connected_tracers,
                    "total_tracers": len(self.tracers),
                    "connection_ratio": connected_tracers / len(self.tracers),
                    "total_connections": total_connections,
                    "connection_density": connection_density,
                    "coordination_score": self.network_coordination_score
                },
                "energy_distribution": total_energy,
                "insights_metrics": {
                    "total_shared_insights": total_insights,
                    "recent_insights": len(self.shared_insights),
                    "average_insights_per_tracer": total_insights / len(self.tracers) if self.tracers else 0
                },
                "performance": {
                    "last_optimization": self.last_network_optimization,
                    "optimization_frequency": 300.0,  # 5 minutes
                    "coordination_efficiency": self.network_coordination_score
                }
            }
            
        except Exception as e:
            logger.error(f"🕷️🍄 [TRACER] Failed to get ecosystem state: {e}")
            return {"integration_enabled": True, "error": str(e)}
    
    # Helper methods for mycelial integration
    
    def _determine_coordinating_tracers(self, alert: TracerAlert) -> List[TracerRole]:
        """Determine which tracers should coordinate based on alert type"""
        
        # Define coordination patterns based on alert characteristics
        if alert.alert_level in [AlertLevel.CRITICAL, AlertLevel.EMERGENCY]:
            # All tracers should be aware of critical alerts
            return list(self.active_tracers)
        
        # Role-specific coordination patterns
        coordination_map = {
            TracerRole.CROW: [TracerRole.BEETLE, TracerRole.WHALE, TracerRole.OWL],  # Pressure alerts need resource and stability
            TracerRole.WHALE: [TracerRole.ANT, TracerRole.BEE],                      # Memory alerts need efficiency tracers
            TracerRole.SPIDER: [TracerRole.ANT, TracerRole.OWL],                     # Network alerts need efficiency and vigilance
            TracerRole.BEETLE: [TracerRole.ANT, TracerRole.MEDIEVAL_BEE],            # Resource alerts need efficiency tracers
            TracerRole.ANT: [TracerRole.BEE, TracerRole.SPIDER],                     # Efficiency alerts need productivity and network
            TracerRole.OWL: [TracerRole.CROW, TracerRole.SPIDER],                    # Vigilance alerts need pressure and network
            TracerRole.BEE: [TracerRole.ANT, TracerRole.MEDIEVAL_BEE],               # Productivity alerts need efficiency
            TracerRole.MEDIEVAL_BEE: [TracerRole.BEETLE, TracerRole.WHALE]           # Legacy alerts need resource and stability
        }
        
        return coordination_map.get(alert.tracer_role, [])
    
    def _rebalance_tracer_energy(self):
        """Rebalance energy across all tracers in the network"""
        
        if not self.mycelial_integration_enabled:
            return
        
        # Calculate total energy across all tracers
        total_energy = {"COGNITIVE_ENERGY": 0, "ANALYTICAL_ENERGY": 0, "COMMUNICATION_ENERGY": 0}
        active_tracers = []
        
        for tracer in self.tracers.values():
            if tracer.mycelial_node_id:
                active_tracers.append(tracer)
                for energy_type, amount in tracer.energy_reserves.items():
                    if energy_type in total_energy:
                        total_energy[energy_type] += amount
        
        if not active_tracers:
            return
        
        # Calculate target energy per tracer
        target_per_tracer = {
            energy_type: total / len(active_tracers)
            for energy_type, total in total_energy.items()
        }
        
        # Redistribute energy (gradual rebalancing)
        for tracer in active_tracers:
            for energy_type, target in target_per_tracer.items():
                current = tracer.energy_reserves.get(energy_type, 0)
                if current < target * 0.7:  # If significantly below target
                    # Request additional energy
                    needed = (target - current) * 0.2  # Gradual increase
                    received = tracer.request_energy_from_network(energy_type, needed)
                    if received > 0:
                        logger.debug(f"🕷️🍄 [TRACER] Rebalanced {energy_type} for {tracer.role.value}: +{received:.1f}")
    
    def distribute_tracer_task(self, task_type: str, task_data: Dict[str, Any], 
                             preferred_tracers: Optional[List[TracerRole]] = None) -> List[str]:
        """Distribute a task across suitable tracers through mycelial network"""
        
        if not self.mycelial_integration_enabled:
            return []
        
        try:
            # Determine suitable tracers for the task
            if preferred_tracers:
                suitable_tracers = preferred_tracers
            else:
                suitable_tracers = self._determine_suitable_tracers(task_type, task_data)
            
            # Distribute task through mycelial network
            distributed_to = []
            
            for tracer_role in suitable_tracers:
                if tracer_role in self.tracers:
                    tracer = self.tracers[tracer_role]
                    
                    # Share task through mycelial network
                    reached = tracer.share_insight_through_mycelium(
                        insight_type="distributed_task",
                        insight_data={
                            "task_type": task_type,
                            "task_data": task_data,
                            "distribution_timestamp": time.time(),
                            "priority": task_data.get("priority", 5)
                        }
                    )
                    
                    if reached:
                        distributed_to.extend(reached)
            
            logger.debug(f"🕷️🍄 [TRACER] Distributed {task_type} task to {len(distributed_to)} tracers")
            return distributed_to
            
        except Exception as e:
            logger.error(f"🕷️🍄 [TRACER] Failed to distribute tracer task: {e}")
            return []
    
    def _determine_suitable_tracers(self, task_type: str, task_data: Dict[str, Any]) -> List[TracerRole]:
        """Determine which tracers are suitable for a given task type"""
        
        # Task-to-tracer mapping based on specializations
        task_mapping = {
            "pressure_monitoring": [TracerRole.CROW, TracerRole.OWL],
            "memory_analysis": [TracerRole.WHALE, TracerRole.ANT],
            "network_analysis": [TracerRole.SPIDER, TracerRole.OWL],
            "efficiency_optimization": [TracerRole.ANT, TracerRole.BEE],
            "resource_management": [TracerRole.BEETLE, TracerRole.MEDIEVAL_BEE],
            "vigilance_task": [TracerRole.OWL, TracerRole.CROW],
            "productivity_tracking": [TracerRole.BEE, TracerRole.ANT],
            "legacy_compatibility": [TracerRole.MEDIEVAL_BEE, TracerRole.BEETLE],
            "general_monitoring": list(TracerRole),  # All tracers for general tasks
        }
        
        return task_mapping.get(task_type, [TracerRole.OWL])  # Default to Owl for unknown tasks

# Global tracer manager instance
_global_tracer_manager: Optional[TracerManager] = None

def get_tracer_manager() -> TracerManager:
    """Get global tracer manager instance"""
    global _global_tracer_manager
    if _global_tracer_manager is None:
        _global_tracer_manager = TracerManager()
    return _global_tracer_manager

def tick_tracer_ecosystem(state: Dict[str, Any]) -> Dict[str, TracerReport]:
    """Convenience function to tick the tracer ecosystem"""
    manager = get_tracer_manager()
    return manager.tick(state)

def register_tracer_alert_callback(callback: Callable[[TracerAlert], None]):
    """Convenience function to register alert callback"""
    manager = get_tracer_manager()
    manager.register_alert_callback(callback)

# Export key classes and functions
__all__ = [
    'TracerManager',
    'TracerAlert',
    'TracerReport',
    'TracerRole',
    'AlertLevel',
    'BaseTracer',
    'CrowTracer',
    'WhaleTracer', 
    'AntTracer',
    'BeetleTracer',
    'SpiderTracer',
    'OwlTracer',
    'BeeTracer',
    'MedievalBeeTracer',
    'get_tracer_manager',
    'tick_tracer_ecosystem',
    'register_tracer_alert_callback'
] 