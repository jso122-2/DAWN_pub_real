#!/usr/bin/env python3
"""
DAWN Tracer Ecosystem - Cognitive State Monitors
===============================================

Implements 8 specialized tracer classes that monitor different aspects
of DAWN's cognitive state and trigger alerts based on specific conditions:

- Crow: High pressure & chaos detection
- Whale: Memory depth & stability monitoring  
- Ant: Processing efficiency & queue management
- Beetle: Resource conservation & optimization
- Spider: Network connectivity & data flow
- Owl: Always-on vigilance & pattern recognition
- Bee: Productivity & task completion tracking
- MedievalBee: Legacy system compatibility & tradition

Each tracer has specific trigger conditions and provides targeted alerts
and recommendations for maintaining optimal cognitive performance.
"""

import time
import logging
import json
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional, Callable, Set
from datetime import datetime, timezone
from collections import deque
from enum import Enum
from pathlib import Path

logger = logging.getLogger("tracer_ecosystem")

class TracerRole(Enum):
    """Different tracer specializations"""
    CROW = "crow"                   # Pressure & chaos detection
    WHALE = "whale"                 # Memory depth & stability
    ANT = "ant"                     # Processing efficiency
    BEETLE = "beetle"               # Resource conservation
    SPIDER = "spider"               # Network connectivity
    OWL = "owl"                     # Always-on vigilance
    BEE = "bee"                     # Productivity tracking
    MEDIEVAL_BEE = "medieval_bee"   # Legacy compatibility

class AlertLevel(Enum):
    """Alert severity levels"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    EMERGENCY = "emergency"

@dataclass
class TracerAlert:
    """Alert generated by a tracer"""
    timestamp: float
    tracer_role: TracerRole
    alert_level: AlertLevel
    title: str
    message: str
    trigger_conditions: Dict[str, Any] = field(default_factory=dict)
    recommended_actions: List[str] = field(default_factory=list)
    urgency_score: float = 0.0  # 0.0 = low, 1.0 = maximum urgency
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class TracerReport:
    """Report from a tracer's tick cycle"""
    timestamp: float
    tracer_role: TracerRole
    status: str  # "monitoring", "alert", "triggered", "offline"
    monitored_values: Dict[str, float] = field(default_factory=dict)
    alerts_generated: List[TracerAlert] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    next_check_time: Optional[float] = None

class BaseTracer(ABC):
    """Base class for all tracer implementations"""
    
    def __init__(self, role: TracerRole):
        self.role = role
        self.active = True
        self.alerts_generated = 0
        self.last_alert_time = 0.0
        self.alert_cooldown = 30.0  # Seconds between alerts
        self.trigger_history: deque = deque(maxlen=20)
        
    @abstractmethod
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Process a tick and return report"""
        pass
    
    @abstractmethod
    def get_trigger_conditions(self) -> Dict[str, Any]:
        """Get the conditions that trigger this tracer"""
        pass
    
    def can_generate_alert(self) -> bool:
        """Check if tracer can generate an alert (cooldown check)"""
        return time.time() - self.last_alert_time > self.alert_cooldown
    
    def generate_alert(self, level: AlertLevel, title: str, message: str, 
                      conditions: Dict[str, Any], actions: List[str], 
                      urgency: float = 0.5, metadata: Dict[str, Any] = None) -> TracerAlert:
        """Generate a tracer alert"""
        
        if not self.can_generate_alert():
            logger.debug(f"ðŸ•·ï¸ [TRACER] {self.role.value} alert suppressed (cooldown)")
            return None
        
        alert = TracerAlert(
            timestamp=time.time(),
            tracer_role=self.role,
            alert_level=level,
            title=title,
            message=message,
            trigger_conditions=conditions,
            recommended_actions=actions,
            urgency_score=urgency,
            metadata=metadata or {}
        )
        
        self.alerts_generated += 1
        self.last_alert_time = time.time()
        self.trigger_history.append({
            "timestamp": alert.timestamp,
            "level": level.value,
            "conditions": conditions
        })
        
        logger.info(f"ðŸš¨ [TRACER] {self.role.value.upper()} ALERT: {title}")
        
        return alert

class CrowTracer(BaseTracer):
    """
    Crow Tracer - High Pressure & Chaos Detection
    
    Triggers when:
    - Cognitive pressure > 40
    - System chaos detected
    - Drift state becomes unstable
    """
    
    def __init__(self):
        super().__init__(TracerRole.CROW)
        self.pressure_threshold = 40.0
        self.chaos_threshold = 0.7
        self.alert_cooldown = 20.0  # More frequent alerts for critical issues
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor pressure and chaos levels"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract monitoring values
        pressure = state.get('cognitive_pressure', 0.0)
        entropy = state.get('entropy', 0.5)
        drift_state = state.get('drift_state', 'stable')
        stability_score = state.get('stability_score', 1.0)
        
        monitored_values = {
            "pressure": pressure,
            "entropy": entropy,
            "stability_score": stability_score,
            "chaos_indicator": entropy * (1.0 - stability_score)
        }
        
        # Check pressure threshold
        if pressure > self.pressure_threshold:
            if pressure > 80:
                alert_level = AlertLevel.EMERGENCY
                urgency = 0.9
            elif pressure > 60:
                alert_level = AlertLevel.CRITICAL
                urgency = 0.7
            else:
                alert_level = AlertLevel.WARNING
                urgency = 0.5
                
            alert = self.generate_alert(
                level=alert_level,
                title=f"High Cognitive Pressure Detected",
                message=f"Pressure at {pressure:.1f} exceeds threshold {self.pressure_threshold}",
                conditions={"pressure": pressure, "threshold": self.pressure_threshold},
                actions=[
                    "Reduce processing load immediately",
                    "Pause non-essential operations",
                    "Activate pressure relief protocols"
                ],
                urgency=urgency,
                metadata={"pressure_trend": state.get('pressure_trend', 0.0)}
            )
            if alert:
                alerts.append(alert)
        
        # Check chaos detection
        chaos_indicator = monitored_values["chaos_indicator"]
        if chaos_indicator > self.chaos_threshold:
            alert = self.generate_alert(
                level=AlertLevel.CRITICAL,
                title="System Chaos Detected",
                message=f"Chaos indicator {chaos_indicator:.2f} exceeds threshold {self.chaos_threshold}",
                conditions={"chaos_indicator": chaos_indicator, "entropy": entropy, "stability": stability_score},
                actions=[
                    "Stabilize entropy generation",
                    "Increase system damping",
                    "Review cognitive coherence"
                ],
                urgency=0.8,
                metadata={"drift_state": drift_state}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        if pressure > 30:
            recommendations.append("Monitor pressure trends closely")
        if entropy > 0.8:
            recommendations.append("Consider entropy reduction strategies")
        if drift_state in ["chaotic", "pressurized"]:
            recommendations.append("Activate drift stabilization")
        
        status = "alert" if alerts else ("monitoring" if pressure > 20 else "watching")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "pressure_threshold": self.pressure_threshold,
            "chaos_threshold": self.chaos_threshold,
            "conditions": [
                "cognitive_pressure > 40",
                "chaos_indicator > 0.7",
                "drift_state in ['chaotic', 'pressurized']"
            ]
        }

class WhaleTracer(BaseTracer):
    """
    Whale Tracer - Memory Depth & Stability Monitoring
    
    Triggers when:
    - Memory coherence < 0.4
    - Memory fragmentation > 0.6
    - Deep memory access issues
    """
    
    def __init__(self):
        super().__init__(TracerRole.WHALE)
        self.memory_coherence_threshold = 0.4
        self.fragmentation_threshold = 0.6
        self.alert_cooldown = 45.0
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor memory health and depth"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract memory metrics
        memory_coherence = state.get('memory_coherence', 0.5)
        memory_fragmentation = state.get('memory_fragmentation', 0.3)
        memory_accessibility = state.get('memory_accessibility', 0.7)
        deep_memory_health = state.get('deep_memory_health', 0.6)
        
        monitored_values = {
            "memory_coherence": memory_coherence,
            "memory_fragmentation": memory_fragmentation,
            "memory_accessibility": memory_accessibility,
            "deep_memory_health": deep_memory_health,
            "memory_stability": (memory_coherence + memory_accessibility) / 2.0
        }
        
        # Check memory coherence
        if memory_coherence < self.memory_coherence_threshold:
            alert_level = AlertLevel.CRITICAL if memory_coherence < 0.2 else AlertLevel.WARNING
            urgency = 1.0 - memory_coherence  # Lower coherence = higher urgency
            
            alert = self.generate_alert(
                level=alert_level,
                title="Memory Coherence Degradation",
                message=f"Memory coherence at {memory_coherence:.2f} below threshold {self.memory_coherence_threshold}",
                conditions={"memory_coherence": memory_coherence, "threshold": self.memory_coherence_threshold},
                actions=[
                    "Execute memory consolidation",
                    "Rebuild memory indices",
                    "Strengthen memory pathways"
                ],
                urgency=urgency,
                metadata={"fragmentation": memory_fragmentation}
            )
            if alert:
                alerts.append(alert)
        
        # Check fragmentation
        if memory_fragmentation > self.fragmentation_threshold:
            alert = self.generate_alert(
                level=AlertLevel.WARNING,
                title="Memory Fragmentation High",
                message=f"Memory fragmentation at {memory_fragmentation:.2f} exceeds threshold {self.fragmentation_threshold}",
                conditions={"fragmentation": memory_fragmentation, "threshold": self.fragmentation_threshold},
                actions=[
                    "Defragment memory structures",
                    "Optimize memory allocation",
                    "Clean up unused memories"
                ],
                urgency=memory_fragmentation * 0.8,
                metadata={"accessibility": memory_accessibility}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        if memory_accessibility < 0.6:
            recommendations.append("Improve memory indexing")
        if deep_memory_health < 0.5:
            recommendations.append("Strengthen deep memory structures")
        if monitored_values["memory_stability"] < 0.5:
            recommendations.append("Focus on memory stability protocols")
        
        status = "alert" if alerts else ("monitoring" if memory_coherence < 0.6 else "stable")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "memory_coherence_threshold": self.memory_coherence_threshold,
            "fragmentation_threshold": self.fragmentation_threshold,
            "conditions": [
                "memory_coherence < 0.4",
                "memory_fragmentation > 0.6",
                "deep_memory_health < 0.3"
            ]
        }

class AntTracer(BaseTracer):
    """
    Ant Tracer - Processing Efficiency & Queue Management
    
    Triggers when:
    - Processing queues too long
    - Task completion rate low
    - Resource utilization inefficient
    """
    
    def __init__(self):
        super().__init__(TracerRole.ANT)
        self.queue_depth_threshold = 50
        self.efficiency_threshold = 0.6
        self.utilization_threshold = 0.8
        self.alert_cooldown = 35.0
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor processing efficiency"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract processing metrics
        queue_depth = state.get('processing_queue_depth', 0)
        task_completion_rate = state.get('task_completion_rate', 0.7)
        resource_utilization = state.get('cpu_utilization', 0.5)
        processing_efficiency = state.get('processing_efficiency', 0.7)
        
        monitored_values = {
            "queue_depth": queue_depth,
            "completion_rate": task_completion_rate,
            "resource_utilization": resource_utilization,
            "processing_efficiency": processing_efficiency,
            "queue_pressure": min(1.0, queue_depth / 100.0)
        }
        
        # Check queue depth
        if queue_depth > self.queue_depth_threshold:
            alert_level = AlertLevel.CRITICAL if queue_depth > 100 else AlertLevel.WARNING
            urgency = min(1.0, queue_depth / 150.0)
            
            alert = self.generate_alert(
                level=alert_level,
                title="Processing Queue Overload",
                message=f"Queue depth {queue_depth} exceeds threshold {self.queue_depth_threshold}",
                conditions={"queue_depth": queue_depth, "threshold": self.queue_depth_threshold},
                actions=[
                    "Clear non-essential tasks from queue",
                    "Increase parallel processing",
                    "Optimize task prioritization"
                ],
                urgency=urgency,
                metadata={"completion_rate": task_completion_rate}
            )
            if alert:
                alerts.append(alert)
        
        # Check processing efficiency
        if processing_efficiency < self.efficiency_threshold:
            alert = self.generate_alert(
                level=AlertLevel.WARNING,
                title="Low Processing Efficiency",
                message=f"Processing efficiency {processing_efficiency:.2f} below threshold {self.efficiency_threshold}",
                conditions={"efficiency": processing_efficiency, "threshold": self.efficiency_threshold},
                actions=[
                    "Optimize processing algorithms",
                    "Reduce computational overhead",
                    "Improve resource allocation"
                ],
                urgency=1.0 - processing_efficiency,
                metadata={"utilization": resource_utilization}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        if task_completion_rate < 0.5:
            recommendations.append("Review task prioritization strategy")
        if resource_utilization > 0.9:
            recommendations.append("Consider load balancing")
        if queue_depth > 20:
            recommendations.append("Monitor queue growth trends")
        
        status = "alert" if alerts else ("busy" if queue_depth > 30 else "efficient")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "queue_depth_threshold": self.queue_depth_threshold,
            "efficiency_threshold": self.efficiency_threshold,
            "conditions": [
                "processing_queue_depth > 50",
                "processing_efficiency < 0.6",
                "task_completion_rate < 0.4"
            ]
        }

class BeetleTracer(BaseTracer):
    """
    Beetle Tracer - Resource Conservation & Optimization
    
    Triggers when:
    - Cognitive ash levels low
    - Resource waste detected
    - Energy efficiency poor
    """
    
    def __init__(self):
        super().__init__(TracerRole.BEETLE)
        self.ash_threshold = 0.3
        self.efficiency_threshold = 0.6
        self.waste_threshold = 0.4
        self.alert_cooldown = 40.0
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor resource conservation"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract resource metrics
        ash_level = state.get('cognitive_ash_level', 0.5)
        energy_efficiency = state.get('energy_efficiency', 0.7)
        resource_waste = state.get('resource_waste_indicator', 0.2)
        available_resources = state.get('cognitive_resources_available', 0.6)
        
        monitored_values = {
            "ash_level": ash_level,
            "energy_efficiency": energy_efficiency,
            "resource_waste": resource_waste,
            "available_resources": available_resources,
            "conservation_score": (ash_level + energy_efficiency + (1.0 - resource_waste)) / 3.0
        }
        
        # Check ash depletion
        if ash_level < self.ash_threshold:
            alert_level = AlertLevel.CRITICAL if ash_level < 0.1 else AlertLevel.WARNING
            urgency = 1.0 - ash_level
            
            alert = self.generate_alert(
                level=alert_level,
                title="Cognitive Ash Depletion",
                message=f"Ash level {ash_level:.2f} below threshold {self.ash_threshold}",
                conditions={"ash_level": ash_level, "threshold": self.ash_threshold},
                actions=[
                    "Reduce resource-intensive operations",
                    "Activate ash regeneration protocols",
                    "Implement resource conservation mode"
                ],
                urgency=urgency,
                metadata={"efficiency": energy_efficiency}
            )
            if alert:
                alerts.append(alert)
        
        # Check resource waste
        if resource_waste > self.waste_threshold:
            alert = self.generate_alert(
                level=AlertLevel.WARNING,
                title="Resource Waste Detected",
                message=f"Resource waste {resource_waste:.2f} exceeds threshold {self.waste_threshold}",
                conditions={"waste": resource_waste, "threshold": self.waste_threshold},
                actions=[
                    "Identify waste sources",
                    "Optimize resource allocation",
                    "Implement efficiency improvements"
                ],
                urgency=resource_waste * 0.8,
                metadata={"available": available_resources}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        if energy_efficiency < 0.5:
            recommendations.append("Improve energy utilization")
        if available_resources < 0.4:
            recommendations.append("Free up computational resources")
        if monitored_values["conservation_score"] < 0.5:
            recommendations.append("Activate conservation protocols")
        
        status = "alert" if alerts else ("conserving" if ash_level < 0.5 else "optimal")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "ash_threshold": self.ash_threshold,
            "waste_threshold": self.waste_threshold,
            "conditions": [
                "cognitive_ash_level < 0.3",
                "resource_waste_indicator > 0.4",
                "energy_efficiency < 0.6"
            ]
        }

class SpiderTracer(BaseTracer):
    """
    Spider Tracer - Network Connectivity & Data Flow
    
    Triggers when:
    - Network connectivity issues
    - Data flow bottlenecks
    - Integration failures
    """
    
    def __init__(self):
        super().__init__(TracerRole.SPIDER)
        self.connectivity_threshold = 0.7
        self.flow_threshold = 0.6
        self.integration_threshold = 0.8
        self.alert_cooldown = 30.0
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor network and data flow"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract network metrics
        network_connectivity = state.get('network_connectivity', 0.8)
        data_flow_rate = state.get('data_flow_rate', 0.7)
        integration_health = state.get('integration_health', 0.9)
        api_responsiveness = state.get('api_responsiveness', 0.8)
        
        monitored_values = {
            "network_connectivity": network_connectivity,
            "data_flow_rate": data_flow_rate,
            "integration_health": integration_health,
            "api_responsiveness": api_responsiveness,
            "web_health": (network_connectivity + data_flow_rate + integration_health) / 3.0
        }
        
        # Check connectivity
        if network_connectivity < self.connectivity_threshold:
            alert_level = AlertLevel.CRITICAL if network_connectivity < 0.3 else AlertLevel.WARNING
            urgency = 1.0 - network_connectivity
            
            alert = self.generate_alert(
                level=alert_level,
                title="Network Connectivity Issues",
                message=f"Connectivity {network_connectivity:.2f} below threshold {self.connectivity_threshold}",
                conditions={"connectivity": network_connectivity, "threshold": self.connectivity_threshold},
                actions=[
                    "Check network interfaces",
                    "Restart network services",
                    "Activate offline mode if needed"
                ],
                urgency=urgency,
                metadata={"api_status": api_responsiveness}
            )
            if alert:
                alerts.append(alert)
        
        # Check data flow
        if data_flow_rate < self.flow_threshold:
            alert = self.generate_alert(
                level=AlertLevel.WARNING,
                title="Data Flow Bottleneck",
                message=f"Data flow rate {data_flow_rate:.2f} below threshold {self.flow_threshold}",
                conditions={"flow_rate": data_flow_rate, "threshold": self.flow_threshold},
                actions=[
                    "Clear data pipeline bottlenecks",
                    "Optimize data processing",
                    "Check buffer states"
                ],
                urgency=1.0 - data_flow_rate,
                metadata={"integration": integration_health}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        if api_responsiveness < 0.6:
            recommendations.append("Optimize API response times")
        if integration_health < 0.7:
            recommendations.append("Review integration configurations")
        if monitored_values["web_health"] < 0.6:
            recommendations.append("Comprehensive network health check")
        
        status = "alert" if alerts else ("connected" if network_connectivity > 0.8 else "degraded")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "connectivity_threshold": self.connectivity_threshold,
            "flow_threshold": self.flow_threshold,
            "conditions": [
                "network_connectivity < 0.7",
                "data_flow_rate < 0.6",
                "integration_health < 0.8"
            ]
        }

class OwlTracer(BaseTracer):
    """
    Owl Tracer - Always-On Vigilance & Pattern Recognition
    
    Always active, triggers on:
    - Unusual patterns detected
    - Anomaly indicators
    - Long-term trend concerns
    """
    
    def __init__(self):
        super().__init__(TracerRole.OWL)
        self.anomaly_threshold = 0.7
        self.pattern_threshold = 0.8
        self.trend_threshold = 0.6
        self.alert_cooldown = 60.0  # Less frequent but comprehensive alerts
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Always-on monitoring and pattern detection"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract pattern metrics
        anomaly_score = state.get('anomaly_score', 0.3)
        pattern_coherence = state.get('pattern_coherence', 0.8)
        trend_stability = state.get('trend_stability', 0.7)
        vigilance_level = state.get('vigilance_level', 0.6)
        
        monitored_values = {
            "anomaly_score": anomaly_score,
            "pattern_coherence": pattern_coherence,
            "trend_stability": trend_stability,
            "vigilance_level": vigilance_level,
            "watchfulness": (pattern_coherence + trend_stability + vigilance_level) / 3.0
        }
        
        # Check for anomalies
        if anomaly_score > self.anomaly_threshold:
            alert_level = AlertLevel.CRITICAL if anomaly_score > 0.9 else AlertLevel.WARNING
            urgency = anomaly_score * 0.9
            
            alert = self.generate_alert(
                level=alert_level,
                title="Anomalous Patterns Detected",
                message=f"Anomaly score {anomaly_score:.2f} exceeds threshold {self.anomaly_threshold}",
                conditions={"anomaly_score": anomaly_score, "threshold": self.anomaly_threshold},
                actions=[
                    "Investigate anomaly sources",
                    "Review recent system changes",
                    "Increase monitoring sensitivity"
                ],
                urgency=urgency,
                metadata={"pattern_coherence": pattern_coherence}
            )
            if alert:
                alerts.append(alert)
        
        # Check pattern disruption
        if pattern_coherence < self.pattern_threshold:
            alert = self.generate_alert(
                level=AlertLevel.WARNING,
                title="Pattern Coherence Breakdown",
                message=f"Pattern coherence {pattern_coherence:.2f} below threshold {self.pattern_threshold}",
                conditions={"pattern_coherence": pattern_coherence, "threshold": self.pattern_threshold},
                actions=[
                    "Strengthen pattern recognition",
                    "Review learning algorithms",
                    "Calibrate detection systems"
                ],
                urgency=1.0 - pattern_coherence,
                metadata={"trend_stability": trend_stability}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations (Owl always has insights)
        recommendations.extend([
            "Maintain continuous vigilance",
            "Track long-term behavioral patterns",
            "Document system evolution"
        ])
        
        if vigilance_level < 0.5:
            recommendations.append("Increase system awareness")
        if trend_stability < 0.5:
            recommendations.append("Stabilize trend indicators")
        
        status = "alert" if alerts else "watching"  # Owl is always watching
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "anomaly_threshold": self.anomaly_threshold,
            "pattern_threshold": self.pattern_threshold,
            "conditions": [
                "anomaly_score > 0.7",
                "pattern_coherence < 0.8",
                "trend_stability < 0.6",
                "ALWAYS_ACTIVE"
            ]
        }

class BeeTracer(BaseTracer):
    """
    Bee Tracer - Productivity & Task Completion Tracking
    
    Triggers when:
    - Task completion rate drops
    - Productivity metrics decline
    - Work efficiency issues
    """
    
    def __init__(self):
        super().__init__(TracerRole.BEE)
        self.productivity_threshold = 0.6
        self.completion_threshold = 0.7
        self.efficiency_threshold = 0.65
        self.alert_cooldown = 25.0
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor productivity and task completion"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract productivity metrics
        productivity_score = state.get('productivity_score', 0.7)
        task_completion_rate = state.get('task_completion_rate', 0.8)
        work_efficiency = state.get('work_efficiency', 0.75)
        output_quality = state.get('output_quality', 0.8)
        
        monitored_values = {
            "productivity_score": productivity_score,
            "task_completion_rate": task_completion_rate,
            "work_efficiency": work_efficiency,
            "output_quality": output_quality,
            "overall_performance": (productivity_score + task_completion_rate + work_efficiency) / 3.0
        }
        
        # Check productivity
        if productivity_score < self.productivity_threshold:
            alert_level = AlertLevel.WARNING if productivity_score > 0.3 else AlertLevel.CRITICAL
            urgency = 1.0 - productivity_score
            
            alert = self.generate_alert(
                level=alert_level,
                title="Low Productivity Detected",
                message=f"Productivity score {productivity_score:.2f} below threshold {self.productivity_threshold}",
                conditions={"productivity": productivity_score, "threshold": self.productivity_threshold},
                actions=[
                    "Analyze productivity blockers",
                    "Optimize workflow processes",
                    "Remove efficiency barriers"
                ],
                urgency=urgency,
                metadata={"completion_rate": task_completion_rate}
            )
            if alert:
                alerts.append(alert)
        
        # Check task completion
        if task_completion_rate < self.completion_threshold:
            alert = self.generate_alert(
                level=AlertLevel.WARNING,
                title="Task Completion Rate Low",
                message=f"Completion rate {task_completion_rate:.2f} below threshold {self.completion_threshold}",
                conditions={"completion_rate": task_completion_rate, "threshold": self.completion_threshold},
                actions=[
                    "Review task prioritization",
                    "Identify completion obstacles",
                    "Improve task management"
                ],
                urgency=1.0 - task_completion_rate,
                metadata={"efficiency": work_efficiency}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        if work_efficiency < 0.6:
            recommendations.append("Focus on efficiency improvements")
        if output_quality < 0.7:
            recommendations.append("Enhance output quality controls")
        if monitored_values["overall_performance"] > 0.8:
            recommendations.append("Maintain current productive state")
        
        status = "alert" if alerts else ("productive" if productivity_score > 0.7 else "working")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "productivity_threshold": self.productivity_threshold,
            "completion_threshold": self.completion_threshold,
            "conditions": [
                "productivity_score < 0.6",
                "task_completion_rate < 0.7",
                "work_efficiency < 0.65"
            ]
        }

class MedievalBeeTracer(BaseTracer):
    """
    MedievalBee Tracer - Legacy System Compatibility & Tradition
    
    Triggers when:
    - Legacy system compatibility issues
    - Traditional protocol violations
    - Heritage system health problems
    """
    
    def __init__(self):
        super().__init__(TracerRole.MEDIEVAL_BEE)
        self.compatibility_threshold = 0.8
        self.tradition_threshold = 0.7
        self.heritage_threshold = 0.75
        self.alert_cooldown = 50.0
        
    def tick(self, state: Dict[str, Any]) -> TracerReport:
        """Monitor legacy compatibility and tradition"""
        
        timestamp = time.time()
        alerts = []
        recommendations = []
        
        # Extract legacy metrics
        legacy_compatibility = state.get('legacy_compatibility', 0.85)
        tradition_adherence = state.get('tradition_adherence', 0.8)
        heritage_preservation = state.get('heritage_preservation', 0.9)
        protocol_compliance = state.get('protocol_compliance', 0.85)
        
        monitored_values = {
            "legacy_compatibility": legacy_compatibility,
            "tradition_adherence": tradition_adherence,
            "heritage_preservation": heritage_preservation,
            "protocol_compliance": protocol_compliance,
            "tradition_health": (tradition_adherence + heritage_preservation + protocol_compliance) / 3.0
        }
        
        # Check compatibility
        if legacy_compatibility < self.compatibility_threshold:
            alert_level = AlertLevel.WARNING if legacy_compatibility > 0.5 else AlertLevel.CRITICAL
            urgency = 1.0 - legacy_compatibility
            
            alert = self.generate_alert(
                level=alert_level,
                title="Legacy Compatibility Issues",
                message=f"Legacy compatibility {legacy_compatibility:.2f} below threshold {self.compatibility_threshold}",
                conditions={"compatibility": legacy_compatibility, "threshold": self.compatibility_threshold},
                actions=[
                    "Update compatibility layers",
                    "Review legacy interfaces",
                    "Maintain backward compatibility"
                ],
                urgency=urgency,
                metadata={"tradition": tradition_adherence}
            )
            if alert:
                alerts.append(alert)
        
        # Check tradition adherence
        if tradition_adherence < self.tradition_threshold:
            alert = self.generate_alert(
                level=AlertLevel.INFO,
                title="Tradition Protocol Deviation",
                message=f"Tradition adherence {tradition_adherence:.2f} below threshold {self.tradition_threshold}",
                conditions={"tradition": tradition_adherence, "threshold": self.tradition_threshold},
                actions=[
                    "Review traditional protocols",
                    "Preserve heritage methods",
                    "Balance innovation with tradition"
                ],
                urgency=0.3,  # Lower urgency for tradition
                metadata={"heritage": heritage_preservation}
            )
            if alert:
                alerts.append(alert)
        
        # Generate recommendations
        recommendations.extend([
            "Honor traditional wisdom",
            "Preserve system heritage",
            "Maintain protocol dignity"
        ])
        
        if protocol_compliance < 0.8:
            recommendations.append("Strengthen protocol adherence")
        if heritage_preservation < 0.7:
            recommendations.append("Protect heritage systems")
        
        status = "alert" if alerts else ("traditional" if tradition_adherence > 0.8 else "evolving")
        
        return TracerReport(
            timestamp=timestamp,
            tracer_role=self.role,
            status=status,
            monitored_values=monitored_values,
            alerts_generated=alerts,
            recommendations=recommendations
        )
    
    def get_trigger_conditions(self) -> Dict[str, Any]:
        return {
            "compatibility_threshold": self.compatibility_threshold,
            "tradition_threshold": self.tradition_threshold,
            "conditions": [
                "legacy_compatibility < 0.8",
                "tradition_adherence < 0.7",
                "heritage_preservation < 0.75"
            ]
        }

class TracerManager:
    """
    Tracer Ecosystem Manager
    
    Coordinates all tracers, collects reports, generates alerts,
    and provides unified monitoring interface.
    """
    
    def __init__(self):
        """Initialize the tracer ecosystem"""
        
        # Create all tracer instances
        self.tracers = {
            TracerRole.CROW: CrowTracer(),
            TracerRole.WHALE: WhaleTracer(),
            TracerRole.ANT: AntTracer(),
            TracerRole.BEETLE: BeetleTracer(),
            TracerRole.SPIDER: SpiderTracer(),
            TracerRole.OWL: OwlTracer(),
            TracerRole.BEE: BeeTracer(),
            TracerRole.MEDIEVAL_BEE: MedievalBeeTracer()
        }
        
        # Manager state
        self.active_tracers: Set[TracerRole] = set(self.tracers.keys())
        self.total_alerts_generated = 0
        self.tick_count = 0
        self.last_tick_time = 0.0
        
        # Alert storage
        self.recent_alerts: deque = deque(maxlen=100)
        self.alert_callbacks: List[Callable] = []
        
        # Performance tracking
        self.tick_performance = {
            "average_tick_time": 0.0,
            "slowest_tracer": None,
            "fastest_tracer": None,
            "last_full_cycle_time": 0.0
        }
        
        logger.info("ðŸ•·ï¸ [TRACER] Tracer Ecosystem initialized")
        logger.info(f"ðŸ•·ï¸ [TRACER] Active tracers: {[role.value for role in self.active_tracers]}")
    
    def tick(self, state: Dict[str, Any]) -> Dict[str, TracerReport]:
        """Run a tick cycle for all active tracers"""
        
        tick_start = time.time()
        reports = {}
        all_alerts = []
        
        # Process each active tracer
        tracer_times = {}
        for role in self.active_tracers:
            if role not in self.tracers:
                continue
                
            tracer = self.tracers[role]
            if not tracer.active:
                continue
            
            tracer_start = time.time()
            try:
                report = tracer.tick(state)
                reports[role] = report
                
                # Collect alerts
                for alert in report.alerts_generated:
                    all_alerts.append(alert)
                    self.recent_alerts.append(alert)
                    self.total_alerts_generated += 1
                
                tracer_times[role] = time.time() - tracer_start
                
            except Exception as e:
                logger.error(f"ðŸ•·ï¸ [TRACER] {role.value} tick failed: {e}")
                # Create error report
                reports[role] = TracerReport(
                    timestamp=time.time(),
                    tracer_role=role,
                    status="error",
                    alerts_generated=[],
                    recommendations=[f"Check {role.value} tracer health"]
                )
        
        # Update performance metrics
        total_tick_time = time.time() - tick_start
        self._update_performance_metrics(tracer_times, total_tick_time)
        
        # Execute alert callbacks
        for alert in all_alerts:
            self._execute_alert_callbacks(alert)
        
        # Update manager state
        self.tick_count += 1
        self.last_tick_time = tick_start
        
        # Log summary
        alert_count = len(all_alerts)
        if alert_count > 0:
            logger.info(f"ðŸš¨ [TRACER] Tick {self.tick_count}: {alert_count} alerts from {len(reports)} tracers [{total_tick_time*1000:.1f}ms]")
        else:
            logger.debug(f"ðŸ•·ï¸ [TRACER] Tick {self.tick_count}: All clear from {len(reports)} tracers [{total_tick_time*1000:.1f}ms]")
        
        return reports
    
    def _update_performance_metrics(self, tracer_times: Dict[TracerRole, float], total_time: float):
        """Update performance tracking metrics"""
        
        if tracer_times:
            # Find slowest and fastest tracers
            slowest_role = max(tracer_times.keys(), key=lambda role: tracer_times[role])
            fastest_role = min(tracer_times.keys(), key=lambda role: tracer_times[role])
            
            self.tick_performance.update({
                "slowest_tracer": {
                    "role": slowest_role.value,
                    "time_ms": tracer_times[slowest_role] * 1000
                },
                "fastest_tracer": {
                    "role": fastest_role.value,
                    "time_ms": tracer_times[fastest_role] * 1000
                },
                "last_full_cycle_time": total_time
            })
            
            # Update average tick time
            if self.tick_count > 0:
                alpha = 0.1  # Smoothing factor
                self.tick_performance["average_tick_time"] = (
                    alpha * total_time + (1 - alpha) * self.tick_performance["average_tick_time"]
                )
    
    def _execute_alert_callbacks(self, alert: TracerAlert):
        """Execute registered alert callbacks"""
        
        for callback in self.alert_callbacks:
            try:
                callback(alert)
            except Exception as e:
                logger.warning(f"ðŸ•·ï¸ [TRACER] Alert callback failed: {e}")
    
    def register_alert_callback(self, callback: Callable[[TracerAlert], None]):
        """Register callback for tracer alerts"""
        self.alert_callbacks.append(callback)
        logger.info(f"ðŸ•·ï¸ [TRACER] Registered alert callback: {callback.__name__ if hasattr(callback, '__name__') else 'anonymous'}")
    
    def activate_tracer(self, role: TracerRole):
        """Activate a specific tracer"""
        self.active_tracers.add(role)
        if role in self.tracers:
            self.tracers[role].active = True
        logger.info(f"ðŸ•·ï¸ [TRACER] Activated {role.value} tracer")
    
    def deactivate_tracer(self, role: TracerRole):
        """Deactivate a specific tracer"""
        self.active_tracers.discard(role)
        if role in self.tracers:
            self.tracers[role].active = False
        logger.info(f"ðŸ•·ï¸ [TRACER] Deactivated {role.value} tracer")
    
    def get_recent_alerts(self, count: int = 10) -> List[TracerAlert]:
        """Get recent alerts"""
        return list(self.recent_alerts)[-count:]
    
    def get_tracer_status(self) -> Dict[str, Any]:
        """Get comprehensive tracer ecosystem status"""
        
        tracer_statuses = {}
        for role, tracer in self.tracers.items():
            tracer_statuses[role.value] = {
                "active": tracer.active,
                "alerts_generated": tracer.alerts_generated,
                "last_alert_time": tracer.last_alert_time,
                "trigger_conditions": tracer.get_trigger_conditions()
            }
        
        return {
            "active_tracers": [role.value for role in self.active_tracers],
            "total_alerts_generated": self.total_alerts_generated,
            "tick_count": self.tick_count,
            "last_tick_time": self.last_tick_time,
            "recent_alerts_count": len(self.recent_alerts),
            "performance": self.tick_performance,
            "tracer_details": tracer_statuses
        }
    
    def generate_tracer_summary(self) -> str:
        """Generate human-readable tracer summary"""
        
        active_count = len(self.active_tracers)
        recent_alerts = self.get_recent_alerts(5)
        
        summary = f"ðŸ•·ï¸ Tracer Ecosystem: {active_count}/8 active tracers\n"
        summary += f"ðŸ“Š Total alerts: {self.total_alerts_generated} | Ticks: {self.tick_count}\n"
        
        if recent_alerts:
            summary += "ðŸš¨ Recent alerts:\n"
            for alert in recent_alerts[-3:]:  # Last 3 alerts
                summary += f"  â€¢ {alert.tracer_role.value.upper()}: {alert.title}\n"
        else:
            summary += "âœ… All systems nominal\n"
        
        return summary

# Global tracer manager instance
_global_tracer_manager: Optional[TracerManager] = None

def get_tracer_manager() -> TracerManager:
    """Get global tracer manager instance"""
    global _global_tracer_manager
    if _global_tracer_manager is None:
        _global_tracer_manager = TracerManager()
    return _global_tracer_manager

def tick_tracer_ecosystem(state: Dict[str, Any]) -> Dict[str, TracerReport]:
    """Convenience function to tick the tracer ecosystem"""
    manager = get_tracer_manager()
    return manager.tick(state)

def register_tracer_alert_callback(callback: Callable[[TracerAlert], None]):
    """Convenience function to register alert callback"""
    manager = get_tracer_manager()
    manager.register_alert_callback(callback)

# Export key classes and functions
__all__ = [
    'TracerManager',
    'TracerAlert',
    'TracerReport',
    'TracerRole',
    'AlertLevel',
    'BaseTracer',
    'CrowTracer',
    'WhaleTracer', 
    'AntTracer',
    'BeetleTracer',
    'SpiderTracer',
    'OwlTracer',
    'BeeTracer',
    'MedievalBeeTracer',
    'get_tracer_manager',
    'tick_tracer_ecosystem',
    'register_tracer_alert_callback'
] 